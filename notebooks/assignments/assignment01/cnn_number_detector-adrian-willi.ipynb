{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djx_mdWTrmhe"
   },
   "source": [
    "\n",
    "# CNN number detector for CompVis assignment 1\n",
    "Student: adrian.willi@hslu.ch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FNi-XJqRr-km"
   },
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from numpy import argmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eS_GVvgFuDHh"
   },
   "outputs": [],
   "source": [
    "def load_dataset() -> None:\n",
    "  \"\"\"\n",
    "  loads mnist dataset and splits it into train and test set\n",
    "\n",
    "  :return trainX, trainY, testX, testY\n",
    "  \"\"\"\n",
    "  (trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "  trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "  testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "  trainY = to_categorical(trainY)\n",
    "  testY = to_categorical(testY)\n",
    "  return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "b0l2ISBCuQgu"
   },
   "outputs": [],
   "source": [
    "def scale_pixels(train, test):\n",
    "  \"\"\"\n",
    "  scales pixels and normalizes images\n",
    "\n",
    "  :train training data\n",
    "  :test testing data\n",
    "  :return normalized training data, normalized testing data\n",
    "  \"\"\"\n",
    "  train_norm = train.astype('float32')\n",
    "  test_norm = test.astype('float32')\n",
    "  train_norm = train_norm / 255.0\n",
    "  test_norm = test_norm / 255.0\n",
    "  return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3c9UwV9_zkkP"
   },
   "outputs": [],
   "source": [
    "def augment_images():\n",
    "  \"\"\"\n",
    "  augments the images \n",
    "\n",
    "  :return img_data_generator \n",
    "  \"\"\"\n",
    "  img_data_generator = ImageDataGenerator(\n",
    "      rotation_range=20,\n",
    "      zoom_range=0.15,\n",
    "      horizontal_flip=True,\n",
    "      vertical_flip=True\n",
    "  )\n",
    "  return img_data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KchxdSNdulmv"
   },
   "outputs": [],
   "source": [
    "def define_model():\n",
    "  \"\"\"\n",
    "  defines the cnn model\n",
    "\n",
    "  :return keras model\n",
    "  \"\"\"\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "  model.add(MaxPooling2D((2, 2)))\n",
    "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "  model.add(MaxPooling2D((2, 2)))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "  model.add(Dense(10, activation='softmax'))\n",
    " \n",
    "  opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1D8bUPXvHdJ",
    "outputId": "7486d174-d404-4c25-9f11-f8b81f109257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               102500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 159,254\n",
      "Trainable params: 159,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "trainX, trainY, testX, testY = load_dataset()\n",
    "# scale pixels and normalize images\n",
    "trainX, testX = scale_pixels(trainX, testX)\n",
    "# define model\n",
    "model = define_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yD4CuHN07wff",
    "outputId": "76bac33c-e83e-4d99-a3bc-c2b80a55bb67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1008 - accuracy: 0.9675 - val_loss: 0.0797 - val_accuracy: 0.9741\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0962 - accuracy: 0.9682 - val_loss: 0.1182 - val_accuracy: 0.9613\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0919 - accuracy: 0.9711 - val_loss: 0.0716 - val_accuracy: 0.9777\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0867 - accuracy: 0.9722 - val_loss: 0.0749 - val_accuracy: 0.9762\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0840 - accuracy: 0.9726 - val_loss: 0.0781 - val_accuracy: 0.9748\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0833 - accuracy: 0.9736 - val_loss: 0.0721 - val_accuracy: 0.9791\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0785 - accuracy: 0.9743 - val_loss: 0.0832 - val_accuracy: 0.9734\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0748 - accuracy: 0.9757 - val_loss: 0.0600 - val_accuracy: 0.9821\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0748 - accuracy: 0.9756 - val_loss: 0.0707 - val_accuracy: 0.9782\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0716 - accuracy: 0.9768 - val_loss: 0.0765 - val_accuracy: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3986149210>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# get image data generator \n",
    "img_data_generator = augment_images()\n",
    "# fit model\n",
    "model.fit(\n",
    "      x = img_data_generator.flow(trainX, trainY, batch_size=batch_size), \n",
    "      epochs=epochs,\n",
    "      validation_data=(testX, testY)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6ClOn-whA_yY"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"final_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-QX7aOPBwEV"
   },
   "source": [
    "## Make prediction on new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BfPrTQtn3MVy"
   },
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "  \"\"\"\n",
    "  loads and preprocesses image\n",
    "\n",
    "  :filename name of the new image\n",
    "  :return preprocessed image\n",
    "  \"\"\"\n",
    "  img = tf.keras.preprocessing.image.load_img(filename, grayscale=True, target_size=(28, 28))\n",
    "  img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "  img = img.reshape(1, 28, 28, 1)\n",
    "  img = img.astype('float32')\n",
    "  img = img / 255.0\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_UuzQTkCa8v",
    "outputId": "f10f4da4-a759-4ffe-c3be-0232972ea97b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3972476dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n",
      "Predicted digit: 3\n"
     ]
    }
   ],
   "source": [
    "# load image\n",
    "img = load_image('test.png')\n",
    "# load model\n",
    "model = load_model('final_model.h5')\n",
    "# predict class\n",
    "predict_value = model.predict(img)\n",
    "digit = argmax(predict_value)\n",
    "print(f\"Predicted digit: {digit}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
