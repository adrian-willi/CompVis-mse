{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUsbO-CuzelY"
   },
   "source": [
    "# DCGAN to generate face images\n",
    "\n",
    "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
    "**Date created:** 2019/04/29<br>\n",
    "**Last modified:** 2021/01/01<br>\n",
    "**Description:** A simple DCGAN trained using `fit()` by overriding `train_step` on CelebA images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp9UlOwqzela"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cR_bn-kYzela"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gdown\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfZ4i3e3zela"
   },
   "source": [
    "## Prepare CelebA data\n",
    "\n",
    "We'll use face images from the CelebA dataset, resized to 64x64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZN7-px_Czelb"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"celeba_gan\")\n",
    "\n",
    "url = \"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\n",
    "output = \"celeba_gan/data.zip\"\n",
    "gdown.download(url, output, quiet=True)\n",
    "\n",
    "with ZipFile(\"celeba_gan/data.zip\", \"r\") as zipobj:\n",
    "    zipobj.extractall(\"celeba_gan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usjx9suFzelb"
   },
   "source": [
    "Create a dataset from our folder, and rescale the images to the [0-1] range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yEjqaORkzelb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n",
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 16:29:08.960299: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-07 16:29:08.960610: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    \"celeba_gan\", label_mode=None, image_size=(64, 64), batch_size=32\n",
    ")\n",
    "dataset = dataset.map(lambda x: x / 255.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qwl4IYbhzelb"
   },
   "source": [
    "Let's display a sample image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KseZ8EU7zelb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 17:07:47.682167: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in dataset:\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vScoJBqJzelc"
   },
   "source": [
    "## Create the discriminator\n",
    "\n",
    "It maps a 64x64 image to a binary classification score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZaelM3K2zelc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 404,801\n",
      "Trainable params: 404,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(64, 64, 3)),\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNvgpd7wzelc"
   },
   "source": [
    "## Create the generator\n",
    "\n",
    "It mirrors the discriminator, replacing `Conv2D` layers with `Conv2DTranspose` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9YHfknCszelc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 8192)              1056768   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      262272    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      524544    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 3)         38403     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,979,651\n",
      "Trainable params: 3,979,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(8 * 8 * 128),\n",
    "        layers.Reshape((8, 8, 128)),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfJnKx75zelc"
   },
   "source": [
    "## Override `train_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "23iI1E_Azeld"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_l0hjDwdzeld"
   },
   "source": [
    "## Create a callback that periodically saves generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KYQlfgHSzeld"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(\"generated_img_%03d_%d.png\" % (epoch, i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msCnbKEKzeld"
   },
   "source": [
    "## Train the end-to-end model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LjhYmeOXzeld",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 17:08:11.133668: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  30/6332 [..............................] - ETA: 1:12:32 - d_loss: 0.6482 - g_loss: 0.8517"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m gan \u001b[38;5;241m=\u001b[39m GAN(discriminator\u001b[38;5;241m=\u001b[39mdiscriminator, generator\u001b[38;5;241m=\u001b[39mgenerator, latent_dim\u001b[38;5;241m=\u001b[39mlatent_dim)\n\u001b[1;32m      4\u001b[0m gan\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      5\u001b[0m     d_optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),\n\u001b[1;32m      6\u001b[0m     g_optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),\n\u001b[1;32m      7\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(),\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mGANMonitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_img\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Master MSE/CompVis/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Master MSE/CompVis/venv/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/Master MSE/CompVis/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Master MSE/CompVis/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Master MSE/CompVis/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/Master MSE/CompVis/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Master MSE/CompVis/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Master MSE/CompVis/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Documents/Master MSE/CompVis/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1  # In practice, use ~100 epochs\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9mbnzC2zele"
   },
   "source": [
    "Some of the last generated images around epoch 30\n",
    "(results keep improving after that):\n",
    "\n",
    "![results](https://i.imgur.com/h5MtQZ7l.png)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "dcgan_overriding_train_step",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
